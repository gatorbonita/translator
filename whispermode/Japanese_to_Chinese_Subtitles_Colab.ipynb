{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üé¨ Japanese to Chinese Subtitle Generator (Whisper Edition)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gatorbonita/translator/blob/main/whispermode/Japanese_to_Chinese_Subtitles_Colab.ipynb)\n",
    "\n",
    "Generate high-quality Chinese subtitles for Japanese videos using:\n",
    "- **Whisper** for transcription (excellent Japanese accuracy!)\n",
    "- **Google Translate** for translation\n",
    "- **FREE GPU** from Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Start\n",
    "\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: **GPU** ‚Üí Save\n",
    "2. **Run all cells**: Runtime ‚Üí Run all (Ctrl+F9)\n",
    "3. **Upload your video** when prompted\n",
    "4. **Wait for processing** (~3-5 min for 30-min video)\n",
    "5. **Download your .srt file**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ‚öôÔ∏è Step 1: Setup Environment\n",
    "\n",
    "This will:\n",
    "- Check if GPU is available\n",
    "- Install required packages\n",
    "- Takes ~2-3 minutes first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-code"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"üîç Checking GPU availability...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, will use CPU (slower)\")\n",
    "    print(\"   Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(\"\\nüì¶ Installing dependencies...\")\n",
    "print(\"This may take 2-3 minutes on first run.\\n\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q moviepy faster-whisper google-cloud-translate python-dotenv loguru\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "credentials"
   },
   "source": [
    "## üîê Step 2: Google Cloud Translation Setup\n",
    "\n",
    "You need Google Cloud credentials **only for translation** (Whisper handles transcription locally).\n",
    "\n",
    "### Option A: Upload Credentials File (Recommended)\n",
    "\n",
    "Run the cell below and upload your `credentials.json` file when prompted.\n",
    "\n",
    "### Option B: Skip Translation (Testing)\n",
    "\n",
    "Set `SKIP_TRANSLATION = True` to skip translation and only test transcription.\n",
    "\n",
    "---\n",
    "\n",
    "**Don't have credentials?** [Quick Setup Guide](https://console.cloud.google.com):\n",
    "1. Enable Cloud Translation API\n",
    "2. Create Service Account ‚Üí Download JSON key\n",
    "3. Upload the JSON file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "credentials-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Set to True to skip translation (for testing transcription only)\n",
    "SKIP_TRANSLATION = False\n",
    "\n",
    "if not SKIP_TRANSLATION:\n",
    "    print(\"üì§ Please upload your Google Cloud credentials JSON file...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        cred_filename = list(uploaded.keys())[0]\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = cred_filename\n",
    "        print(f\"‚úÖ Credentials loaded: {cred_filename}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No credentials uploaded. Will skip translation.\")\n",
    "        SKIP_TRANSLATION = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Translation disabled. Will only generate Japanese transcripts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Step 3: Configuration\n",
    "\n",
    "Adjust settings here:\n",
    "\n",
    "- **WHISPER_MODEL**: `tiny`, `base`, `small`, `medium`, `large-v3`\n",
    "  - `medium` = Best balance (recommended)\n",
    "  - `large-v3` = Best quality (slower)\n",
    "  - `small` = Faster, good quality\n",
    "\n",
    "- **TARGET_LANGUAGE**: `zh-CN` (Simplified) or `zh-TW` (Traditional)\n",
    "\n",
    "- **DEVICE**: `auto` (uses GPU if available), `cpu`, or `cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-code"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "WHISPER_MODEL = 'medium'  # Options: tiny, base, small, medium, large-v3\n",
    "TARGET_LANGUAGE = 'zh-CN'  # zh-CN = Simplified, zh-TW = Traditional\n",
    "DEVICE = 'auto'  # auto = use GPU if available\n",
    "\n",
    "print(f\"‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Whisper Model: {WHISPER_MODEL}\")\n",
    "print(f\"   Target Language: {TARGET_LANGUAGE}\")\n",
    "print(f\"   Device: {DEVICE}\")\n",
    "print(f\"   Translation: {'Disabled' if SKIP_TRANSLATION else 'Enabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "functions"
   },
   "source": [
    "## üîß Step 4: Load Functions\n",
    "\n",
    "Loading all the necessary functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "functions-code"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass",
    "from pathlib import Path",
    "from typing import List",
    "from moviepy.editor import VideoFileClip, AudioFileClip",
    "from faster_whisper import WhisperModel",
    "from google.cloud import translate_v2 as translate",
    "from google.oauth2 import service_account",
    "import time",
    "from datetime import datetime",
    "",
    "@dataclass",
    "class TranscriptSegment:",
    "    \"\"\"Represents a subtitle segment.\"\"\"",
    "    text: str",
    "    start_time: float",
    "    end_time: float",
    "    confidence: float = 1.0",
    "",
    "# Audio Extraction",
    "def extract_audio(video_path, output_dir='/content'):",
    "    \"\"\"Extract audio from video.\"\"\"",
    "    print(f\"\\nüéµ Extracting audio from video...\")",
    "    video = VideoFileClip(video_path)",
    "    ",
    "    if video.audio is None:",
    "        raise Exception(\"Video has no audio track!\")",
    "    ",
    "    audio_path = f\"{output_dir}/audio_temp.wav\"",
    "    video.audio.write_audiofile(",
    "        audio_path,",
    "        fps=16000,",
    "        nbytes=2,",
    "        codec='pcm_s16le',",
    "        ffmpeg_params=['-ac', '1'],",
    "        logger=None,",
    "        verbose=False",
    "    )",
    "    ",
    "    duration = video.duration",
    "    video.close()",
    "    ",
    "    print(f\"‚úÖ Audio extracted: {duration:.1f} seconds\")",
    "    return audio_path, duration",
    "",
    "# Whisper Transcription",
    "def transcribe_with_whisper(audio_path, model_size='medium', device='auto'):",
    "    \"\"\"Transcribe audio with Whisper.\"\"\"",
    "    print(f\"\\nüé§ Transcribing with Whisper ({model_size} model)...\")",
    "    ",
    "    # Determine device and compute type",
    "    if device == 'auto':",
    "        if torch.cuda.is_available():",
    "            device = 'cuda'",
    "            compute_type = 'float16'",
    "            print(\"   Using GPU acceleration\")",
    "        else:",
    "            device = 'cpu'",
    "            compute_type = 'int8'",
    "            print(\"   Using CPU\")",
    "    elif device == 'cuda':",
    "        compute_type = 'float16'",
    "    else:",
    "        compute_type = 'int8'",
    "    ",
    "    # Load model",
    "    print(\"   Loading Whisper model...\")",
    "    model = WhisperModel(model_size, device=device, compute_type=compute_type)",
    "    ",
    "    # Transcribe",
    "    print(\"   Transcribing... (this may take a few minutes)\")",
    "    segments_generator, info = model.transcribe(",
    "        audio_path,",
    "        language='ja',",
    "        beam_size=5,",
    "        word_timestamps=True,",
    "        vad_filter=True,",
    "        vad_parameters=dict(min_silence_duration_ms=500)",
    "    )",
    "    ",
    "    print(f\"   Detected language: {info.language} (confidence: {info.language_probability:.2%})\")",
    "    ",
    "    # CRITICAL FIX: Convert generator to list immediately!",
    "    # faster-whisper returns a generator that can only be iterated once",
    "    print(\"   Converting segments to list...\")",
    "    segments = list(segments_generator)",
    "    print(f\"   ‚≠ê Whisper found {len(segments)} raw segments covering full audio\")",
    "    ",
    "    # Process segments",
    "    transcript_segments = []",
    "    print(\"   Processing segments into subtitles...\")",
    "    for i, segment in enumerate(segments):",
    "        if (i + 1) % 20 == 0:",
    "            print(f\"      ‚ñ∂ Processing segment {i+1}/{len(segments)}...\")",
    "        if segment.words:",
    "            # Group words into subtitle-friendly segments",
    "            word_segments = create_segments_from_words(segment.words)",
    "            transcript_segments.extend(word_segments)",
    "        else:",
    "            transcript_segments.append(",
    "                TranscriptSegment(",
    "                    text=segment.text.strip(),",
    "                    start_time=segment.start,",
    "                    end_time=segment.end,",
    "                    confidence=1.0",
    "                )",
    "            )",
    "    ",
    "    print(f\"‚úÖ Transcription complete: {len(transcript_segments)} segments\")",
    "    return transcript_segments",
    "",
    "def create_segments_from_words(words, max_duration=5.0, max_chars=80):",
    "    \"\"\"Group words into subtitle segments.\"\"\"",
    "    segments = []",
    "    current_words = []",
    "    current_start = None",
    "    sentence_endings = {'„ÄÇ', 'ÔºÅ', 'Ôºü', '„ÄÅ'}",
    "    ",
    "    for word in words:",
    "        if current_start is None:",
    "            current_start = word.start",
    "        ",
    "        current_words.append(word.word)",
    "        current_end = word.end",
    "        duration = current_end - current_start",
    "        text = ''.join(current_words).strip()",
    "        ",
    "        should_finalize = False",
    "        if duration >= max_duration or len(text) >= max_chars:",
    "            should_finalize = True",
    "        elif any(text.endswith(punct) for punct in sentence_endings):",
    "            if len(text) > 10 or duration > 1.0:",
    "                should_finalize = True",
    "        ",
    "        if should_finalize:",
    "            segments.append(TranscriptSegment(",
    "                text=text,",
    "                start_time=current_start,",
    "                end_time=current_end,",
    "                confidence=1.0",
    "            ))",
    "            current_words = []",
    "            current_start = None",
    "    ",
    "    if current_words:",
    "        text = ''.join(current_words).strip()",
    "        if text:",
    "            segments.append(TranscriptSegment(",
    "                text=text,",
    "                start_time=current_start,",
    "                end_time=current_end,",
    "                confidence=1.0",
    "            ))",
    "    ",
    "    return segments",
    "",
    "# Translation",
    "def translate_segments(segments, target_language='zh-CN', batch_size=128):",
    "    \"\"\"Translate segments to Chinese.\"\"\"",
    "    if not segments:",
    "        return []",
    "    ",
    "    print(f\"\\nüåè Translating to {target_language}...\")",
    "    ",
    "    # Initialize translator",
    "    cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')",
    "    credentials = service_account.Credentials.from_service_account_file(cred_path)",
    "    client = translate.Client(credentials=credentials)",
    "    ",
    "    translated_segments = []",
    "    ",
    "    # Process in batches",
    "    for i in range(0, len(segments), batch_size):",
    "        batch = segments[i:i + batch_size]",
    "        texts = [seg.text for seg in batch]",
    "        ",
    "        # Translate with retry",
    "        for attempt in range(3):",
    "            try:",
    "                results = client.translate(texts, target_language=target_language, source_language='ja')",
    "                if isinstance(results, dict):",
    "                    translated_texts = [results['translatedText']]",
    "                else:",
    "                    translated_texts = [r['translatedText'] for r in results]",
    "                break",
    "            except Exception as e:",
    "                if attempt == 2:",
    "                    raise Exception(f\"Translation failed: {e}\")",
    "                time.sleep(2 ** attempt)",
    "        ",
    "        # Create translated segments",
    "        for segment, translated_text in zip(batch, translated_texts):",
    "            translated_segments.append(TranscriptSegment(",
    "                text=translated_text,",
    "                start_time=segment.start_time,",
    "                end_time=segment.end_time,",
    "                confidence=segment.confidence",
    "            ))",
    "        ",
    "        if len(segments) > batch_size:",
    "            print(f\"   Translated {min(i + batch_size, len(segments))}/{len(segments)} segments\")",
    "    ",
    "    print(f\"‚úÖ Translation complete: {len(translated_segments)} segments\")",
    "    return translated_segments",
    "",
    "# SRT Generation",
    "def generate_srt(segments, output_path):",
    "    \"\"\"Generate SRT subtitle file.\"\"\"",
    "    print(f\"\\nüìù Generating SRT file...\")",
    "    ",
    "    # Merge short segments",
    "    merged = merge_short_segments(segments)",
    "    ",
    "    with open(output_path, 'w', encoding='utf-8') as f:",
    "        for i, segment in enumerate(merged, start=1):",
    "            f.write(f\"{i}\\n\")",
    "            start_ts = format_timestamp(segment.start_time)",
    "            end_ts = format_timestamp(segment.end_time)",
    "            f.write(f\"{start_ts} --> {end_ts}\\n\")",
    "            f.write(f\"{segment.text}\\n\\n\")",
    "    ",
    "    print(f\"‚úÖ SRT file created: {output_path}\")",
    "    return output_path",
    "",
    "def format_timestamp(seconds):",
    "    \"\"\"Convert seconds to SRT timestamp format.\"\"\"",
    "    hours = int(seconds // 3600)",
    "    minutes = int((seconds % 3600) // 60)",
    "    secs = int(seconds % 60)",
    "    millisecs = int((seconds % 1) * 1000)",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}\"",
    "",
    "def merge_short_segments(segments, min_duration=1.0, max_chars=80):",
    "    \"\"\"Merge segments that are too short.\"\"\"",
    "    if not segments:",
    "        return []",
    "    ",
    "    merged = []",
    "    current = None",
    "    ",
    "    for segment in segments:",
    "        if current is None:",
    "            current = TranscriptSegment(",
    "                text=segment.text,",
    "                start_time=segment.start_time,",
    "                end_time=segment.end_time,",
    "                confidence=segment.confidence",
    "            )",
    "            continue",
    "        ",
    "        duration = current.end_time - current.start_time",
    "        combined_text = current.text + \" \" + segment.text",
    "        ",
    "        should_merge = (",
    "            duration < min_duration or",
    "            (len(combined_text) <= max_chars and segment.start_time - current.end_time < 1.0)",
    "        )",
    "        ",
    "        if should_merge:",
    "            current.text = combined_text",
    "            current.end_time = segment.end_time",
    "        else:",
    "            merged.append(current)",
    "            current = TranscriptSegment(",
    "                text=segment.text,",
    "                start_time=segment.start_time,",
    "                end_time=segment.end_time,",
    "                confidence=segment.confidence",
    "            )",
    "    ",
    "    if current is not None:",
    "        merged.append(current)",
    "    ",
    "    return merged",
    "",
    "print(\"‚úÖ Functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## üì§ Step 5: Upload Video\n",
    "\n",
    "Upload your Japanese video file. Supported formats:\n",
    "- MP4, MKV, AVI, MOV, WebM, and more\n",
    "\n",
    "**Note**: Large files (>100MB) may take time to upload. Consider using Google Drive for very large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-code"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Please upload your video file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    video_filename = list(uploaded.keys())[0]\n",
    "    video_path = f\"/content/{video_filename}\"\n",
    "    print(f\"\\n‚úÖ Video uploaded: {video_filename}\")\n",
    "    print(f\"   Size: {len(uploaded[video_filename]) / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    raise Exception(\"No video file uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "process"
   },
   "source": [
    "## üöÄ Step 6: Process Video\n",
    "\n",
    "This will:\n",
    "1. Extract audio from video\n",
    "2. Transcribe with Whisper (Japanese)\n",
    "3. Translate to Chinese (if enabled)\n",
    "4. Generate SRT subtitle file\n",
    "\n",
    "**Estimated time** (30-min video with GPU):\n",
    "- Audio extraction: ~30 seconds\n",
    "- Whisper transcription: ~2-4 minutes\n",
    "- Translation: ~10 seconds\n",
    "- **Total: ~3-5 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process-code"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Step 1: Extract audio\n",
    "    audio_path, duration = extract_audio(video_path)\n",
    "    \n",
    "    # Step 2: Transcribe with Whisper\n",
    "    japanese_segments = transcribe_with_whisper(\n",
    "        audio_path,\n",
    "        model_size=WHISPER_MODEL,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    # Step 3: Translate (if enabled)\n",
    "    if SKIP_TRANSLATION:\n",
    "        print(\"\\n‚ö†Ô∏è  Skipping translation (disabled)\")\n",
    "        final_segments = japanese_segments\n",
    "        output_suffix = \"_ja.srt\"  # Japanese only\n",
    "    else:\n",
    "        final_segments = translate_segments(\n",
    "            japanese_segments,\n",
    "            target_language=TARGET_LANGUAGE\n",
    "        )\n",
    "        output_suffix = f\"_{TARGET_LANGUAGE}.srt\"\n",
    "    \n",
    "    # Step 4: Generate SRT\n",
    "    video_name = Path(video_filename).stem\n",
    "    output_path = f\"/content/{video_name}{output_suffix}\"\n",
    "    generate_srt(final_segments, output_path)\n",
    "    \n",
    "    # Cleanup\n",
    "    import os\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "    \n",
    "    # Summary\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ SUBTITLE GENERATION COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Video duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
    "    print(f\"Processing time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"Segments: {len(final_segments)}\")\n",
    "    print(f\"Model: {WHISPER_MODEL}\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    SUBTITLE_FILE = output_path\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üì• Step 7: Download Subtitle File\n",
    "\n",
    "Download your generated subtitle file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-code"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "try:\n",
    "    if 'SUBTITLE_FILE' in globals() and os.path.exists(SUBTITLE_FILE):\n",
    "        print(f\"üì• Downloading: {SUBTITLE_FILE}\")\n",
    "        files.download(SUBTITLE_FILE)\n",
    "        print(\"\\n‚úÖ Download started! Check your browser's download folder.\")\n",
    "        print(\"\\nüì∫ To use:\")\n",
    "        print(\"   1. Open video in VLC player\")\n",
    "        print(\"   2. Subtitle ‚Üí Add Subtitle File\")\n",
    "        print(\"   3. Select the downloaded .srt file\")\n",
    "    else:\n",
    "        print(\"‚ùå No subtitle file found. Please run Step 6 first.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Download error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preview"
   },
   "source": [
    "## üëÄ (Optional) Preview Subtitles\n",
    "\n",
    "Preview the first 10 subtitle entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preview-code"
   },
   "outputs": [],
   "source": [
    "if 'SUBTITLE_FILE' in globals() and os.path.exists(SUBTITLE_FILE):\n",
    "    print(\"üìñ Preview of first 10 subtitles:\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with open(SUBTITLE_FILE, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        preview_lines = []\n",
    "        count = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            preview_lines.append(line)\n",
    "            if line.strip() == '' and len(preview_lines) > 1:\n",
    "                count += 1\n",
    "                if count >= 10:\n",
    "                    break\n",
    "        \n",
    "        print(''.join(preview_lines))\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå No subtitle file found. Please run Step 6 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "---\n",
    "\n",
    "## üí° Tips & Troubleshooting\n",
    "\n",
    "### For Better Results:\n",
    "- ‚úÖ **Use GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "- ‚úÖ **Better quality**: Use `large-v3` model (slower)\n",
    "- ‚úÖ **Faster processing**: Use `small` or `base` model\n",
    "- ‚úÖ **Clear audio**: Remove background music if possible\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**\"Out of memory\"**\n",
    "- Use smaller model: `WHISPER_MODEL = 'small'`\n",
    "- Runtime ‚Üí Factory reset runtime\n",
    "\n",
    "**\"No GPU detected\"**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
    "- Restart runtime if needed\n",
    "\n",
    "**\"Translation error\"**\n",
    "- Check credentials file is uploaded\n",
    "- Verify Translation API is enabled\n",
    "- Set `SKIP_TRANSLATION = True` to test transcription only\n",
    "\n",
    "**\"Video upload fails\"**\n",
    "- For files >100MB, use Google Drive:\n",
    "  ```python\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  video_path = '/content/drive/MyDrive/your-video.mp4'\n",
    "  ```\n",
    "\n",
    "### Model Comparison:\n",
    "\n",
    "| Model | VRAM | Speed | Quality |\n",
    "|-------|------|-------|--------|\n",
    "| tiny | 1GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê |\n",
    "| base | 1GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |\n",
    "| small | 2GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| medium | 5GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| large-v3 | 10GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "\n",
    "**Colab Free GPU**: ~15GB VRAM, can run up to `large-v3`\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub Repository**: [gatorbonita/translator](https://github.com/gatorbonita/translator)\n",
    "- **Whisper Edition Docs**: [whispermode/README.md](https://github.com/gatorbonita/translator/blob/main/whispermode/README.md)\n",
    "- **Google Cloud Setup**: [Translation API Guide](https://cloud.google.com/translate/docs/setup)\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**üåü Enjoying this tool? Star the repo on GitHub!**\n",
    "\n",
    "Made with ‚ù§Ô∏è using Whisper + Google Translate\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}