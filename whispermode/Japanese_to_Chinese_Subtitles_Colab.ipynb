{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üé¨ Japanese to Chinese Subtitle Generator (Whisper Edition)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gatorbonita/translator/blob/main/whispermode/Japanese_to_Chinese_Subtitles_Colab.ipynb)\n",
    "\n",
    "Generate high-quality Chinese subtitles for Japanese videos using:\n",
    "- **Whisper** for transcription (excellent Japanese accuracy!)\n",
    "- **Google Translate** for translation\n",
    "- **FREE GPU** from Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Start\n",
    "\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: **GPU** ‚Üí Save\n",
    "2. **Run all cells**: Runtime ‚Üí Run all (Ctrl+F9)\n",
    "3. **Upload your video** when prompted\n",
    "4. **Wait for processing** (~3-5 min for 30-min video)\n",
    "5. **Download your .srt file**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ‚öôÔ∏è Step 1: Setup Environment\n",
    "\n",
    "This will:\n",
    "- Check if GPU is available\n",
    "- Install required packages\n",
    "- Takes ~2-3 minutes first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-code"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(\"üîç Checking GPU availability...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected, will use CPU (slower)\")\n",
    "    print(\"   Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "print(\"\\nüì¶ Installing dependencies...\")\n",
    "print(\"This may take 2-3 minutes on first run.\\n\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q moviepy faster-whisper google-cloud-translate python-dotenv loguru\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "credentials"
   },
   "source": [
    "## üîê Step 2: Google Cloud Translation Setup\n",
    "\n",
    "You need Google Cloud credentials **only for translation** (Whisper handles transcription locally).\n",
    "\n",
    "### Option A: Upload Credentials File (Recommended)\n",
    "\n",
    "Run the cell below and upload your `credentials.json` file when prompted.\n",
    "\n",
    "### Option B: Skip Translation (Testing)\n",
    "\n",
    "Set `SKIP_TRANSLATION = True` to skip translation and only test transcription.\n",
    "\n",
    "---\n",
    "\n",
    "**Don't have credentials?** [Quick Setup Guide](https://console.cloud.google.com):\n",
    "1. Enable Cloud Translation API\n",
    "2. Create Service Account ‚Üí Download JSON key\n",
    "3. Upload the JSON file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "credentials-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "# Set to True to skip translation (for testing transcription only)\n",
    "SKIP_TRANSLATION = False\n",
    "\n",
    "if not SKIP_TRANSLATION:\n",
    "    print(\"üì§ Please upload your Google Cloud credentials JSON file...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        cred_filename = list(uploaded.keys())[0]\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = cred_filename\n",
    "        print(f\"‚úÖ Credentials loaded: {cred_filename}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No credentials uploaded. Will skip translation.\")\n",
    "        SKIP_TRANSLATION = True\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Translation disabled. Will only generate Japanese transcripts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Step 3: Configuration\n",
    "\n",
    "Adjust settings here:\n",
    "\n",
    "- **WHISPER_MODEL**: `tiny`, `base`, `small`, `medium`, `large-v3`\n",
    "  - `medium` = Best balance (recommended)\n",
    "  - `large-v3` = Best quality (slower)\n",
    "  - `small` = Faster, good quality\n",
    "\n",
    "- **TARGET_LANGUAGE**: `zh-CN` (Simplified) or `zh-TW` (Traditional)\n",
    "\n",
    "- **DEVICE**: `auto` (uses GPU if available), `cpu`, or `cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config-code"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "WHISPER_MODEL = 'medium'  # Options: tiny, base, small, medium, large-v3\n",
    "TARGET_LANGUAGE = 'zh-CN'  # zh-CN = Simplified, zh-TW = Traditional\n",
    "DEVICE = 'auto'  # auto = use GPU if available\n",
    "\n",
    "print(f\"‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Whisper Model: {WHISPER_MODEL}\")\n",
    "print(f\"   Target Language: {TARGET_LANGUAGE}\")\n",
    "print(f\"   Device: {DEVICE}\")\n",
    "print(f\"   Translation: {'Disabled' if SKIP_TRANSLATION else 'Enabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "functions"
   },
   "source": [
    "## üîß Step 4: Load Functions\n",
    "\n",
    "Loading all the necessary functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "functions-code"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip\n",
    "from faster_whisper import WhisperModel\n",
    "from google.cloud import translate_v2 as translate\n",
    "from google.oauth2 import service_account\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class TranscriptSegment:\n",
    "    \"\"\"Represents a subtitle segment.\"\"\"\n",
    "    text: str\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    confidence: float = 1.0\n",
    "\n",
    "# Audio Extraction\n",
    "def extract_audio(video_path, output_dir='/content'):\n",
    "    \"\"\"Extract audio from video.\"\"\"\n",
    "    print(f\"\\nüéµ Extracting audio from video...\")\n",
    "    video = VideoFileClip(video_path)\n",
    "    \n",
    "    if video.audio is None:\n",
    "        raise Exception(\"Video has no audio track!\")\n",
    "    \n",
    "    audio_path = f\"{output_dir}/audio_temp.wav\"\n",
    "    video.audio.write_audiofile(\n",
    "        audio_path,\n",
    "        fps=16000,\n",
    "        nbytes=2,\n",
    "        codec='pcm_s16le',\n",
    "        ffmpeg_params=['-ac', '1'],\n",
    "        logger=None,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    duration = video.duration\n",
    "    video.close()\n",
    "    \n",
    "    print(f\"‚úÖ Audio extracted: {duration:.1f} seconds\")\n",
    "    return audio_path, duration\n",
    "\n",
    "# Whisper Transcription\n",
    "def transcribe_with_whisper(audio_path, model_size='medium', device='auto'):\n",
    "    \"\"\"Transcribe audio with Whisper.\"\"\"\n",
    "    print(f\"\\nüé§ Transcribing with Whisper ({model_size} model)...\")\n",
    "    \n",
    "    # Determine device and compute type\n",
    "    if device == 'auto':\n",
    "        if torch.cuda.is_available():\n",
    "            device = 'cuda'\n",
    "            compute_type = 'float16'\n",
    "            print(\"   Using GPU acceleration\")\n",
    "        else:\n",
    "            device = 'cpu'\n",
    "            compute_type = 'int8'\n",
    "            print(\"   Using CPU\")\n",
    "    elif device == 'cuda':\n",
    "        compute_type = 'float16'\n",
    "    else:\n",
    "        compute_type = 'int8'\n",
    "    \n",
    "    # Load model\n",
    "    print(\"   Loading Whisper model...\")\n",
    "    model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
    "    \n",
    "    # Transcribe\n",
    "    print(\"   Transcribing... (this may take a few minutes)\")\n",
    "    segments, info = model.transcribe(\n",
    "        audio_path,\n",
    "        language='ja',\n",
    "        beam_size=5,\n",
    "        word_timestamps=True,\n",
    "        vad_filter=True,\n",
    "        vad_parameters=dict(min_silence_duration_ms=500)\n",
    "    )\n",
    "    \n",
    "    print(f\"   Detected language: {info.language} (confidence: {info.language_probability:.2%})\")\n",
    "    \n",
    "    # Process segments\n",
    "    transcript_segments = []\n",
    "    for segment in segments:\n",
    "        if segment.words:\n",
    "            # Group words into subtitle-friendly segments\n",
    "            word_segments = create_segments_from_words(segment.words)\n",
    "            transcript_segments.extend(word_segments)\n",
    "        else:\n",
    "            transcript_segments.append(\n",
    "                TranscriptSegment(\n",
    "                    text=segment.text.strip(),\n",
    "                    start_time=segment.start,\n",
    "                    end_time=segment.end,\n",
    "                    confidence=1.0\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    print(f\"‚úÖ Transcription complete: {len(transcript_segments)} segments\")\n",
    "    return transcript_segments\n",
    "\n",
    "def create_segments_from_words(words, max_duration=5.0, max_chars=80):\n",
    "    \"\"\"Group words into subtitle segments.\"\"\"\n",
    "    segments = []\n",
    "    current_words = []\n",
    "    current_start = None\n",
    "    sentence_endings = {'„ÄÇ', 'ÔºÅ', 'Ôºü', '„ÄÅ'}\n",
    "    \n",
    "    for word in words:\n",
    "        if current_start is None:\n",
    "            current_start = word.start\n",
    "        \n",
    "        current_words.append(word.word)\n",
    "        current_end = word.end\n",
    "        duration = current_end - current_start\n",
    "        text = ''.join(current_words).strip()\n",
    "        \n",
    "        should_finalize = False\n",
    "        if duration >= max_duration or len(text) >= max_chars:\n",
    "            should_finalize = True\n",
    "        elif any(text.endswith(punct) for punct in sentence_endings):\n",
    "            if len(text) > 10 or duration > 1.0:\n",
    "                should_finalize = True\n",
    "        \n",
    "        if should_finalize:\n",
    "            segments.append(TranscriptSegment(\n",
    "                text=text,\n",
    "                start_time=current_start,\n",
    "                end_time=current_end,\n",
    "                confidence=1.0\n",
    "            ))\n",
    "            current_words = []\n",
    "            current_start = None\n",
    "    \n",
    "    if current_words:\n",
    "        text = ''.join(current_words).strip()\n",
    "        if text:\n",
    "            segments.append(TranscriptSegment(\n",
    "                text=text,\n",
    "                start_time=current_start,\n",
    "                end_time=current_end,\n",
    "                confidence=1.0\n",
    "            ))\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Translation\n",
    "def translate_segments(segments, target_language='zh-CN', batch_size=128):\n",
    "    \"\"\"Translate segments to Chinese.\"\"\"\n",
    "    if not segments:\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nüåè Translating to {target_language}...\")\n",
    "    \n",
    "    # Initialize translator\n",
    "    cred_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "    credentials = service_account.Credentials.from_service_account_file(cred_path)\n",
    "    client = translate.Client(credentials=credentials)\n",
    "    \n",
    "    translated_segments = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(segments), batch_size):\n",
    "        batch = segments[i:i + batch_size]\n",
    "        texts = [seg.text for seg in batch]\n",
    "        \n",
    "        # Translate with retry\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                results = client.translate(texts, target_language=target_language, source_language='ja')\n",
    "                if isinstance(results, dict):\n",
    "                    translated_texts = [results['translatedText']]\n",
    "                else:\n",
    "                    translated_texts = [r['translatedText'] for r in results]\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt == 2:\n",
    "                    raise Exception(f\"Translation failed: {e}\")\n",
    "                time.sleep(2 ** attempt)\n",
    "        \n",
    "        # Create translated segments\n",
    "        for segment, translated_text in zip(batch, translated_texts):\n",
    "            translated_segments.append(TranscriptSegment(\n",
    "                text=translated_text,\n",
    "                start_time=segment.start_time,\n",
    "                end_time=segment.end_time,\n",
    "                confidence=segment.confidence\n",
    "            ))\n",
    "        \n",
    "        if len(segments) > batch_size:\n",
    "            print(f\"   Translated {min(i + batch_size, len(segments))}/{len(segments)} segments\")\n",
    "    \n",
    "    print(f\"‚úÖ Translation complete: {len(translated_segments)} segments\")\n",
    "    return translated_segments\n",
    "\n",
    "# SRT Generation\n",
    "def generate_srt(segments, output_path):\n",
    "    \"\"\"Generate SRT subtitle file.\"\"\"\n",
    "    print(f\"\\nüìù Generating SRT file...\")\n",
    "    \n",
    "    # Merge short segments\n",
    "    merged = merge_short_segments(segments)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for i, segment in enumerate(merged, start=1):\n",
    "            f.write(f\"{i}\\n\")\n",
    "            start_ts = format_timestamp(segment.start_time)\n",
    "            end_ts = format_timestamp(segment.end_time)\n",
    "            f.write(f\"{start_ts} --> {end_ts}\\n\")\n",
    "            f.write(f\"{segment.text}\\n\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ SRT file created: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    \"\"\"Convert seconds to SRT timestamp format.\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    millisecs = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}\"\n",
    "\n",
    "def merge_short_segments(segments, min_duration=1.0, max_chars=80):\n",
    "    \"\"\"Merge segments that are too short.\"\"\"\n",
    "    if not segments:\n",
    "        return []\n",
    "    \n",
    "    merged = []\n",
    "    current = None\n",
    "    \n",
    "    for segment in segments:\n",
    "        if current is None:\n",
    "            current = TranscriptSegment(\n",
    "                text=segment.text,\n",
    "                start_time=segment.start_time,\n",
    "                end_time=segment.end_time,\n",
    "                confidence=segment.confidence\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        duration = current.end_time - current.start_time\n",
    "        combined_text = current.text + \" \" + segment.text\n",
    "        \n",
    "        should_merge = (\n",
    "            duration < min_duration or\n",
    "            (len(combined_text) <= max_chars and segment.start_time - current.end_time < 1.0)\n",
    "        )\n",
    "        \n",
    "        if should_merge:\n",
    "            current.text = combined_text\n",
    "            current.end_time = segment.end_time\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            current = TranscriptSegment(\n",
    "                text=segment.text,\n",
    "                start_time=segment.start_time,\n",
    "                end_time=segment.end_time,\n",
    "                confidence=segment.confidence\n",
    "            )\n",
    "    \n",
    "    if current is not None:\n",
    "        merged.append(current)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "print(\"‚úÖ Functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": [
    "## üì§ Step 5: Upload Video\n",
    "\n",
    "Upload your Japanese video file. Supported formats:\n",
    "- MP4, MKV, AVI, MOV, WebM, and more\n",
    "\n",
    "**Note**: Large files (>100MB) may take time to upload. Consider using Google Drive for very large files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload-code"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Please upload your video file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    video_filename = list(uploaded.keys())[0]\n",
    "    video_path = f\"/content/{video_filename}\"\n",
    "    print(f\"\\n‚úÖ Video uploaded: {video_filename}\")\n",
    "    print(f\"   Size: {len(uploaded[video_filename]) / (1024*1024):.1f} MB\")\n",
    "else:\n",
    "    raise Exception(\"No video file uploaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "process"
   },
   "source": [
    "## üöÄ Step 6: Process Video\n",
    "\n",
    "This will:\n",
    "1. Extract audio from video\n",
    "2. Transcribe with Whisper (Japanese)\n",
    "3. Translate to Chinese (if enabled)\n",
    "4. Generate SRT subtitle file\n",
    "\n",
    "**Estimated time** (30-min video with GPU):\n",
    "- Audio extraction: ~30 seconds\n",
    "- Whisper transcription: ~2-4 minutes\n",
    "- Translation: ~10 seconds\n",
    "- **Total: ~3-5 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process-code"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Step 1: Extract audio\n",
    "    audio_path, duration = extract_audio(video_path)\n",
    "    \n",
    "    # Step 2: Transcribe with Whisper\n",
    "    japanese_segments = transcribe_with_whisper(\n",
    "        audio_path,\n",
    "        model_size=WHISPER_MODEL,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    # Step 3: Translate (if enabled)\n",
    "    if SKIP_TRANSLATION:\n",
    "        print(\"\\n‚ö†Ô∏è  Skipping translation (disabled)\")\n",
    "        final_segments = japanese_segments\n",
    "        output_suffix = \"_ja.srt\"  # Japanese only\n",
    "    else:\n",
    "        final_segments = translate_segments(\n",
    "            japanese_segments,\n",
    "            target_language=TARGET_LANGUAGE\n",
    "        )\n",
    "        output_suffix = f\"_{TARGET_LANGUAGE}.srt\"\n",
    "    \n",
    "    # Step 4: Generate SRT\n",
    "    video_name = Path(video_filename).stem\n",
    "    output_path = f\"/content/{video_name}{output_suffix}\"\n",
    "    generate_srt(final_segments, output_path)\n",
    "    \n",
    "    # Cleanup\n",
    "    import os\n",
    "    if os.path.exists(audio_path):\n",
    "        os.remove(audio_path)\n",
    "    \n",
    "    # Summary\n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ SUBTITLE GENERATION COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Video duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
    "    print(f\"Processing time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    print(f\"Segments: {len(final_segments)}\")\n",
    "    print(f\"Model: {WHISPER_MODEL}\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    SUBTITLE_FILE = output_path\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üì• Step 7: Download Subtitle File\n",
    "\n",
    "Download your generated subtitle file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-code"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "try:\n",
    "    if 'SUBTITLE_FILE' in globals() and os.path.exists(SUBTITLE_FILE):\n",
    "        print(f\"üì• Downloading: {SUBTITLE_FILE}\")\n",
    "        files.download(SUBTITLE_FILE)\n",
    "        print(\"\\n‚úÖ Download started! Check your browser's download folder.\")\n",
    "        print(\"\\nüì∫ To use:\")\n",
    "        print(\"   1. Open video in VLC player\")\n",
    "        print(\"   2. Subtitle ‚Üí Add Subtitle File\")\n",
    "        print(\"   3. Select the downloaded .srt file\")\n",
    "    else:\n",
    "        print(\"‚ùå No subtitle file found. Please run Step 6 first.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Download error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "preview"
   },
   "source": [
    "## üëÄ (Optional) Preview Subtitles\n",
    "\n",
    "Preview the first 10 subtitle entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "preview-code"
   },
   "outputs": [],
   "source": [
    "if 'SUBTITLE_FILE' in globals() and os.path.exists(SUBTITLE_FILE):\n",
    "    print(\"üìñ Preview of first 10 subtitles:\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with open(SUBTITLE_FILE, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        preview_lines = []\n",
    "        count = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            preview_lines.append(line)\n",
    "            if line.strip() == '' and len(preview_lines) > 1:\n",
    "                count += 1\n",
    "                if count >= 10:\n",
    "                    break\n",
    "        \n",
    "        print(''.join(preview_lines))\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå No subtitle file found. Please run Step 6 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "---\n",
    "\n",
    "## üí° Tips & Troubleshooting\n",
    "\n",
    "### For Better Results:\n",
    "- ‚úÖ **Use GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "- ‚úÖ **Better quality**: Use `large-v3` model (slower)\n",
    "- ‚úÖ **Faster processing**: Use `small` or `base` model\n",
    "- ‚úÖ **Clear audio**: Remove background music if possible\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**\"Out of memory\"**\n",
    "- Use smaller model: `WHISPER_MODEL = 'small'`\n",
    "- Runtime ‚Üí Factory reset runtime\n",
    "\n",
    "**\"No GPU detected\"**\n",
    "- Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
    "- Restart runtime if needed\n",
    "\n",
    "**\"Translation error\"**\n",
    "- Check credentials file is uploaded\n",
    "- Verify Translation API is enabled\n",
    "- Set `SKIP_TRANSLATION = True` to test transcription only\n",
    "\n",
    "**\"Video upload fails\"**\n",
    "- For files >100MB, use Google Drive:\n",
    "  ```python\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  video_path = '/content/drive/MyDrive/your-video.mp4'\n",
    "  ```\n",
    "\n",
    "### Model Comparison:\n",
    "\n",
    "| Model | VRAM | Speed | Quality |\n",
    "|-------|------|-------|--------|\n",
    "| tiny | 1GB | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê |\n",
    "| base | 1GB | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |\n",
    "| small | 2GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| medium | 5GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| large-v3 | 10GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "\n",
    "**Colab Free GPU**: ~15GB VRAM, can run up to `large-v3`\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub Repository**: [gatorbonita/translator](https://github.com/gatorbonita/translator)\n",
    "- **Whisper Edition Docs**: [whispermode/README.md](https://github.com/gatorbonita/translator/blob/main/whispermode/README.md)\n",
    "- **Google Cloud Setup**: [Translation API Guide](https://cloud.google.com/translate/docs/setup)\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**üåü Enjoying this tool? Star the repo on GitHub!**\n",
    "\n",
    "Made with ‚ù§Ô∏è using Whisper + Google Translate\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
